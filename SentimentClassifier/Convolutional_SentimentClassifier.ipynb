{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding\n",
    "from tensorflow.keras.layers import SpatialDropout1D, Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import modin.pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'model_output/conv'\n",
    "\n",
    "# training\n",
    "EPOCHS = 4\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# vector-space embedding\n",
    "N_DIM = 64\n",
    "N_UNIQUE_WORDS = 5000\n",
    "MAX_REVIEW_LENGTH = 400 # we incresed the size of max review, cuz ConV can handle longers\n",
    "PAD_TYPE = TRUNC_TYPE = 'pre'\n",
    "DROP_EMBED = 0.2 # this is for Embedding Layer\n",
    "\n",
    "# convolutional layer architecture\n",
    "N_CONV = 256 # filters a.k.a. kernels\n",
    "K_CONV = 3 # kernel length, looking for triplets tokens\n",
    "\n",
    "# neural network architecture\n",
    "N_DENSE = 256\n",
    "DROPOUT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_valid, y_valid) = imdb.load_data(num_words = N_UNIQUE_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=MAX_REVIEW_LENGTH,\n",
    "                      padding=PAD_TYPE, truncating=TRUNC_TYPE, value=0)\n",
    "\n",
    "X_valid = pad_sequences(X_valid, maxlen=MAX_REVIEW_LENGTH,\n",
    "                      padding=PAD_TYPE, truncating=TRUNC_TYPE, value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConV Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first hidden layer --> Embedding Layer\n",
    "model.add(Embedding(N_UNIQUE_WORDS, N_DIM, input_length=MAX_REVIEW_LENGTH))\n",
    "model.add(SpatialDropout1D(DROP_EMBED))\n",
    "\n",
    "\n",
    "# second hidden layer --> Dense Layer\n",
    "model.add(Conv1D(N_CONV, K_CONV, activation='relu')) # image icin Conv2D kullanilir\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(DROPOUT))\n",
    "\n",
    "# third hidden layer --> Dense Layer\n",
    "model.add(Dense(N_DENSE, activation='relu'))\n",
    "model.add(Dropout(DROPOUT))\n",
    "\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 400, 64)           320000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 400, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 398, 256)          49408     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 435,457\n",
      "Trainable params: 435,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 25s 1ms/sample - loss: 0.4850 - accuracy: 0.7426 - val_loss: 0.2989 - val_accuracy: 0.8752\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 24s 970us/sample - loss: 0.2758 - accuracy: 0.8874 - val_loss: 0.3320 - val_accuracy: 0.8594\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 24s 974us/sample - loss: 0.2110 - accuracy: 0.9168 - val_loss: 0.2672 - val_accuracy: 0.8877\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 24s 973us/sample - loss: 0.1627 - accuracy: 0.9385 - val_loss: 0.3113 - val_accuracy: 0.8792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe0c4895d10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "         batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1,\n",
    "         validation_data=(X_valid, y_valid),\n",
    "         callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the best epoch is 3rd epoch so we need to load that one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.03.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred)\n",
    "_ = plt.axvline(0.5, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.93128288\n"
     ]
    }
   ],
   "source": [
    "pct_auc = roc_auc_score(y_valid, y_pred)*100.0\n",
    "print(pct_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_y_pred = []\n",
    "for y in y_pred:\n",
    "    float_y_pred.append(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(list(zip(float_y_pred, y_valid)), columns=['y_pred', 'y_valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038827</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.991014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.924881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.677172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.990328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_pred  y_valid\n",
       "0  0.038827        0\n",
       "1  0.991014        1\n",
       "2  0.924881        1\n",
       "3  0.677172        0\n",
       "4  0.990328        1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

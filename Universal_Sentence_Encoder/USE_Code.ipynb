{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buradaki kritik husus, calistigin directory'nin parentinda `sentence_wise_email` folderini onun icinde `module` folderini ve en icte de `module_useT` folderini create etmek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0x ./\n",
      "x ./tfhub_module.pb\n",
      "x ./variables/\n",
      " 97  745M   97  727M    0     0  12.4M      0  0:00:59  0:00:58  0:00:01 18.9M8M      0  0:00:58  0:00:38  0:00:20 16.6M9M      0  0:00:57  0:00:39  0:00:18 16.5M\n",
      "x ./variables/variables.index\n",
      "x ./assets/\n",
      "100  745M  100  745M    0     0  12.5M      0  0:00:59  0:00:59 --:--:-- 20.1M\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!curl -L \"https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed\" | tar -zxvC ../sentence_wise_email/module/module_useT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.Module(\"../sentence_wise_email/module/module_useT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: Elephant\n",
      "Embedding size: 512\n",
      "Embedding[0.044984735548496246, -0.05743393301963806, 0.0022114701569080353,...]\n",
      "\n",
      "Message: I am a sentence for which I would like to get its embedding.\n",
      "Embedding size: 512\n",
      "Embedding[0.05568017438054085, -0.009607937186956406, 0.006246284581720829,...]\n",
      "\n",
      "Message: Universal Sentence Encoder embeddings also support short paragraphs. There is no hard limit on how long the paragraph is. Roughly, the longer the more 'diluted' the embedding will be.\n",
      "Embedding size: 512\n",
      "Embedding[0.03874938562512398, 0.0765201598405838, -0.0007945825927890837,...]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute a representation for each message, showing various lengths supported.\n",
    "word = \"Elephant\"\n",
    "sentence = \"I am a sentence for which I would like to get its embedding.\"\n",
    "paragraph = (\n",
    "    \"Universal Sentence Encoder embeddings also support short paragraphs. \"\n",
    "    \"There is no hard limit on how long the paragraph is. Roughly, the longer \"\n",
    "    \"the more 'diluted' the embedding will be.\")\n",
    "messages = [word, sentence, paragraph]\n",
    "# Reduce logging output.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    message_embeddings = session.run(embed(messages))\n",
    "for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
    "        print(\"Message: {}\".format(messages[i]))\n",
    "        print(\"Embedding size: {}\".format(len(message_embedding)))\n",
    "        message_embedding_snippet = \", \".join((str(x) for x in        message_embedding[:3]))\n",
    "        print(\"Embedding[{},...]\\n\".\n",
    "                   format(message_embedding_snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00021282, -0.04443965,  0.03926145, ...,  0.0483016 ,\n",
       "        -0.11913303,  0.03370819],\n",
       "       [ 0.01778569, -0.0519203 , -0.00792321, ..., -0.01799901,\n",
       "        -0.09819184,  0.06020728],\n",
       "       [-0.00748424, -0.0240158 ,  0.01762745, ...,  0.09334016,\n",
       "        -0.11837555,  0.00603596],\n",
       "       [-0.03505319, -0.01932572, -0.0324861 , ...,  0.00356431,\n",
       "        -0.08239801,  0.03887842],\n",
       "       [-0.05111802, -0.0309066 ,  0.03542012, ..., -0.01343899,\n",
       "        -0.10434885, -0.03150062]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embed_useT(module):\n",
    "    with tf.Graph().as_default():\n",
    "        sentences = tf.placeholder(tf.string)\n",
    "        embed = hub.Module(module)\n",
    "        embeddings = embed(sentences)\n",
    "        session = tf.train.MonitoredSession()\n",
    "    return lambda x: session.run(embeddings, {sentences: x})\n",
    "embed_fn = embed_useT('../sentence_wise_email/module/module_useT')\n",
    "messages = [\n",
    "    \"we are sorry for the inconvenience\",\n",
    "    \"we are sorry for the delay\",\n",
    "    \"we regret for your inconvenience\",\n",
    "    \"we don't deliver to baner region in pune\",\n",
    "    \"we will get you the best possible rate\"\n",
    "]\n",
    "embed_fn(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9999999 , 0.87426376, 0.80048907, 0.2380786 , 0.4646979 ],\n",
       "       [0.87426376, 1.0000002 , 0.60501504, 0.25081366, 0.4493389 ],\n",
       "       [0.80048907, 0.60501504, 0.9999998 , 0.1784874 , 0.41954657],\n",
       "       [0.2380786 , 0.25081366, 0.1784874 , 0.99999976, 0.24955791],\n",
       "       [0.4646979 , 0.4493389 , 0.41954657, 0.24955791, 1.0000002 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_matrix = embed_fn(messages)\n",
    "np.inner(encoding_matrix, encoding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It takes similarity matrix (generated from sentence encoder) as input and gives index of redundant statements\n",
    "def redundant_sent_idx(sim_matrix):\n",
    "    dup_idx = [] \n",
    "    for i in range(sim_matrix.shape[0]):\n",
    "        if i not in dup_idx:\n",
    "            tmp = [t+i+1 for t in list(np.where( sim_matrix[i][i+1:] > 0.8 )[0])]\n",
    "            dup_idx.extend(tmp)\n",
    "    return dup_idx\n",
    "#indexes of duplicate statements.\n",
    "dup_indexes  = redundant_sent_idx(np.inner(encoding_matrix,\n",
    "                                           encoding_matrix))\n",
    "unique_messages = np.delete(np.array(messages), dup_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['we are sorry for the inconvenience',\n",
       "       \"we don't deliver to baner region in pune\",\n",
       "       'we will get you the best possible rate'], dtype='<U40')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(['we are sorry for the inconvenience',\n",
    "       \"we don't deliver to baner region in pune\",\n",
    "       'we will get you the best possible rate'], dtype='<U40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16033182, 0.24214168, 0.30527407, 0.321598  , 0.27426553,\n",
       "        0.07302819, 0.30970466, 0.3245443 , 0.0890827 , 0.29725873,\n",
       "        0.2704302 ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is not a greetings\n"
     ]
    }
   ],
   "source": [
    "greets = [\"What's up?\",\n",
    " 'It is a pleasure to meet you.',\n",
    " 'How do you do?',\n",
    " 'Top of the morning to you!',\n",
    " 'Hi',\n",
    " 'How are you doing?',\n",
    " 'Hello',\n",
    " 'Greetings!',\n",
    " 'Hi, How is it going?',\n",
    " 'Hi, nice to meet you.',\n",
    " 'Nice to meet you.']\n",
    "greet_matrix = embed_fn(greets)\n",
    "test_text = \"I will remove my car?\"\n",
    "test_embed = embed_fn([test_text])\n",
    "np.inner(test_embed, greet_matrix)\n",
    "sim_matrix  = np.inner(test_embed, greet_matrix)\n",
    "if sim_matrix.max() > 0.8:\n",
    "    print(\"it is a greetings\")\n",
    "else:\n",
    "    print(\"it is not a greetings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
